{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "medium-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# to print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "rocky-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the data - download the dataset if no data_dir is specified.\n",
    "# so we have the data already in 'data/' for you\n",
    "\n",
    "# Importing CNN/DailyMail articles dataset\n",
    "train_stream_fnction = trax.data.TFDS('cnn_dailymail',\n",
    "                                 data_dir='../news_data/',\n",
    "                                 keys=('article', 'highlights'),\n",
    "                                 train=True)\n",
    "\n",
    "# This should be much faster as the data is downloaded already.\n",
    "eval_stream_fnction = trax.data.TFDS('cnn_dailymail',\n",
    "                                data_dir='../news_data/',\n",
    "                                keys=('article', 'highlights'),\n",
    "                                train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-ribbon",
   "metadata": {},
   "source": [
    "#### Create tokenize and detokenize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "million-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need create helper functions to tokenize and detokenize data. Tokenise converts a text sentence to its\n",
    "# corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
    "# similarly we need to have detokenize function to reconvert the tokens to its sentence\n",
    "\n",
    "def tokenize(input_str,EOS=1):\n",
    "    \"\"\" convert input string to a feature dictionary\"\"\"\n",
    "#     trax.data.tokenize method takes streams and returns streams, we user iter to have one elment stream\n",
    "    input_sting=next(trax.data.tokenize(iter([input_str]),\n",
    "                                       vocab_dir='vocab_dir/',\n",
    "                                       vocab_file='summarize32k.subword.subwords'))\n",
    "#     put EOS at the end of sentence\n",
    "    return list(input_string)+[EOS]\n",
    "\n",
    "def detokenize(input_integers):\n",
    "    \"\"\"convert input intergers to string\"\"\"\n",
    "    string_converted=trax.data.detokenize(input_integers,\n",
    "                                        vocab_dir='vocab_dir/',\n",
    "                                        vocab_file='summarize32k.subword.subwords')\n",
    "    \n",
    "    return wrapper.fill(string_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fantastic-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model and preprocessing\n",
    "# language models only predicts next work,we concatenate inputs with target and seperate them\n",
    "# with a seperator and concatenate them. Further padding masks are used 0s and 1s in input and targets \n",
    "# respectively. So the focus is model to pay attention on summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "pending-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask tokens\n",
    "SEP=0 #Padding or separator\n",
    "EOS=1 #end of token sentence\n",
    "\n",
    "# # Now lets concatenate input tokens and targets using 0 as seperator\n",
    "def preprocess(stream):\n",
    "    \"\"\"get the data stream and seperate with 0, stream data comming with articles and summary\"\"\"\n",
    "    for (article,summary) in stream:\n",
    "        combine=np.array(list(article)+[EOS,SEP]+list(summary)+[EOS])\n",
    "        mask=[0]*(len(list(article))+2)+[1]*(len(list(summary))+1)\n",
    "        yield combine,combine,np.array(mask)\n",
    "\n",
    "# # make data pipeline as follows\n",
    "input_pipeline=trax.data.Serial(\n",
    "#     first tokennize\n",
    "    trax.data.Tokenize(vocab_dir='vocab_dir/',\n",
    "                        vocab_file='summarize32k.subword.subwords'),\n",
    "#     now use the above function preprocess\n",
    "    preprocess,\n",
    "#     need to filter out the strings longer than 2018\n",
    "    trax.data.FilterByLength(2048)\n",
    ")\n",
    "\n",
    "# # Apply above pipeline to both train and evaluation data\n",
    "train_stream=input_pipeline(train_stream_fnction())\n",
    "eval_stream=input_pipeline(eval_stream_fnction())\n",
    "\n",
    "# get one by one\n",
    "train_input,train_target,train_mask=next(train_stream)\n",
    "# train and target shoud be same language model\n",
    "assert sum((train_input-train_target)**2)==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "amber-inclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example mask:\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prints mask, 0s on article, 1s on summary\n",
    "print(f'Single example mask:\\n\\n {train_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "conservative-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example:\n",
      "\n",
      " A curry house has been fined £3,000 after two dead mice were\n",
      "discovered next to a sack of onions. Health inspectors also found\n",
      "rodent droppings in the kitchen and food stored inside a dirty shed\n",
      "when they visited Khans Tandoori and Balti Takeaway in Portsmouth,\n",
      "Hampshire. The kitchen sink was also dry and had no soap and the staff\n",
      "toilet was in a poor condition, while layers of dirt, grease and\n",
      "debris had built up in the areas where food was handled and stored.\n",
      "Khans Tandoori and Balti Takeaway in Portsmouth, Hampshire, has been\n",
      "fined £3,000 after these dead mice were discovered next to a sack of\n",
      "onions . Magistrates ordered the restaurant to pay a £1,800 fine,\n",
      "£1,117 in costs and a £36 victim surcharge, after owner of Harold\n",
      "Southsea Ltd, admitted five charges under hygiene legislation on\n",
      "behalf of the takeaway. Health officer Christopher Larkin from\n",
      "Portsmouth City Council had discovered the dead mice on sticky boards\n",
      "that had been put out to catch the vermin when he visited the\n",
      "restaurant last July. Staff were forced to close the restaurant to\n",
      "make emergency repairs, and it was only allowed to reopen once the\n",
      "kitchen had been cleaned and disinfected, and the food moved out of\n",
      "the lean-to shed. Other improvements were also made. Magistrates\n",
      "ordered the restaurant (pictured) to pay a £1,800 fine, £1,117 in\n",
      "costs and a £36 victim surcharge, after owner of Harold Southsea Ltd,\n",
      "admitted five charges under hygiene legislation on behalf of the\n",
      "takeaway . Inspectors found that the kitchen sink was dry and had no\n",
      "soap, while the staff toilet was in a poor condition . 'Food hygiene\n",
      "is of prime importance and we cannot allow poor standards and\n",
      "behaviour like this,' said Alan Cufley, head of environmental health\n",
      "at the Portsmouth City Council. 'When problems are found, we try to\n",
      "work with businesses to help them improve, but if necessary we will\n",
      "take appropriate action, including prosecution, to protect the\n",
      "public.' The restaurant admitted failing to maintain the premises in\n",
      "good repair, failing to maintain them in a clean condition, failing to\n",
      "protect food from risk of contamination, failing to protect the\n",
      "kitchen from pest entry, and failing to control pests. These bags of\n",
      "cleaning products were discovered when inspectors visited the takeaway\n",
      "in July last year . Mr Khan, who owns the takeaway, said: 'It's been\n",
      "cleaned up. Basically we have done everything that's required. 'We\n",
      "have been trying to improve it for the future. We have never had it\n",
      "this bad before. 'We have taken measures to have a clean kitchen.'\n",
      "Council environment chief Robert New said: 'There's just no excuse for\n",
      "mice to be in kitchens. 'It has been a priority since I took over.\n",
      "It's about protecting the public.' He added there has been a change of\n",
      "strategy at the council, with officers now tackling 'medium to bad'\n",
      "offenders as a priority, rather than looking at each restaurant in\n",
      "turn. Health inspectors also found food being stored inside this dirty\n",
      "shed. The takeaway was forced to close, and could only reopen once the\n",
      "restaurant had been cleaned, and the food removed from the lean-to .\n",
      "Mouse droppings were found on the floor of the kitchen, and in a goods\n",
      "store used by staff .<EOS><pad>Rodentdroppings found in the Khans\n",
      "Tandoori and Balti Takeaway kitchen . Food was being stored in a dirty\n",
      "shed, and the kitchen sink had no soap . Dead mice were discovered on\n",
      "sticky boards intended to catch them . Takeaway fined after owner\n",
      "admitted hygiene charges on its behalf .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
    "print(f'Single example:\\n\\n {detokenize(train_input)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "muslim-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs are in different lengths and padding them with 0s will wast computational resource so good approach \n",
    "# would be group the strings to specific sizes and process, ww use buckets to create batched generators\n",
    "# buckets are defined based on boundaries and batch sizes, batch size[i] signifies the \n",
    "# batch size for the items with length < boundaries[i], so we use batch size 4 of length<512, 8 of length<256,16 of sentence lewnght <128 so on\n",
    "\n",
    "boundaries =[128,256,512,1024]\n",
    "batch_size=[16,8,4,2,1]\n",
    "\n",
    "# now create the stream\n",
    "train_batch_stream=trax.data.BucketByLength(boundaries,batch_size)(train_stream)\n",
    "eval_batch_stream=trax.data.BucketByLength(boundaries,batch_size)(eval_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "funky-craps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different articles will be produced every time\n",
    "input_batch,_,mask_batch=next(train_batch_stream)\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dangerous-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    7,  6062, 19330,    21, 15570,  3385, 10077,    23,    46,\n",
       "        11555,   527,  1147,  1865, 23891,  6412,   379,   514,  3558,\n",
       "         8998,  5754,   527, 17296,  6933, 18453,  2337,   320, 26377,\n",
       "           14,   186,  6157,  2416,    23,    46, 11555,   527,  1147,\n",
       "         1865, 23891,  6412,     3,  3385, 10077,  6503, 20889, 24810,\n",
       "           16,    72,   441,     6,   104,     6, 23324,  7511,    41,\n",
       "          806,  1019,   134,   809,    15,  9158, 15019,   410,   395,\n",
       "          799,    28,  2145,   809,  9744,  5429,   812,     3,     9,\n",
       "         2823,     6,   104,     6,   292, 13431,  1353,   592,   233,\n",
       "           19,  8272,   527,  1147,  1865, 23891,  6412,   214,   213,\n",
       "           72,   331,    35,  6122,    87,   527,    15,  4175,   117,\n",
       "          143,    18,    46,   576,   132,   213,  2297,   138,  1099,\n",
       "         5400,    22,   379, 17895,   102,   213,   347,     2,   368,\n",
       "        10077,   127,    22,  1425,   117,  3965, 19330,    21,    80,\n",
       "          691,   213,  4967,   527,   213,  2145,  1782,    13,  1006,\n",
       "           13,    18,    46,  3965, 19330,    21,     3,   326, 11498,\n",
       "           25, 14320, 21690,   186,    13,   793,   213,   864,   412,\n",
       "          196,  1782,    13,   410,    28,  3489,   157,   186,    36,\n",
       "          527,   105,   897,   156,   412,    28,  7570,  5163,   114,\n",
       "         1682,  1480,   229,  2685,   231,     3,    13,  4386,    28,\n",
       "         3489,     2, 22057,  4955,   809,   126,   186,    41, 18999,\n",
       "        13066,    17,   539,  2002,     9,  3558,  2028,   969,    22,\n",
       "           62,    19,  4132, 26977,   320,   126,   809,    15,  2300,\n",
       "          132,   213,   531,  1782,    13,    18,   133,   213,   884,\n",
       "          107, 22825,  7633,  7824,   640,   127,   285,    13,     7,\n",
       "           75,    19,   416,   320,   126,  1248,   310,   116,    44,\n",
       "         1782,    13,   169, 14149,    72,  1210,     6,   104,     6,\n",
       "          292,   331,   132,   213,   797,  1779,   126,  1019,   156,\n",
       "         2002,   863,   213,  2145,   103,  1353,  6402,   368, 10077,\n",
       "          793, 14010,  6240,   320,  4132,   117,  8191,    16,    80,\n",
       "          506,   331,   186,   285,    22,  7359,  2125,   117,   506,\n",
       "          186,  3336,  1099, 10940,  6394, 20443,     2,  1779,  8161,\n",
       "         3648,   320,   213,   395,     2,   793, 11576,   692,   368,\n",
       "        10077,    40, 24462,   134,  4601,  4067,   223,    41, 29725,\n",
       "            4,   165,  8191,    16,     2,    41, 29725,     4,   371,\n",
       "          211,   213,  1082,     2,    33,   288,  2754,    13,  1134,\n",
       "         3898,   171,  4195,    22,  7359,  2125,   117,   506,   186,\n",
       "         3336,  8503,   117,    69,   793,   156,    22,  1353,   996,\n",
       "         1019,   381,   186,   441,     6,   104,     6, 23324,     2,\n",
       "        21585,    20,    28,  2635,  3898,   368,  6394, 20443,   127,\n",
       "            3,   380,   527,   213,   331,  6402,    22, 21302,    17,\n",
       "           68,  1838,   936,   192,   131,  1353, 14960,     4,    95,\n",
       "          132,   979,   527,    28, 16283, 12627,     2,   192,   213,\n",
       "           54,  2663,   131,  1425,   117, 26313,    20,    80,  1248,\n",
       "          213,   117, 17066,    20,     2,  4483,  1808,    80,  8998,\n",
       "         1782,    69,  1353,  6963,    16,   156,    61,   186,   246,\n",
       "            3,    13,  1425, 26313,    14,     3,    13,  1353,  1429,\n",
       "          320, 10924,  5849,     4,   103,   236,     2,   103,  1353,\n",
       "        12967,  8800,     3,    69,    40,    15, 14114,    64,   186,\n",
       "         1353,  5091,    16,   809,   156, 11969,     7,    69,   127,\n",
       "         4601, 27634,     4,  1918, 29725,     4,    26,   545,   413,\n",
       "          320,   126,   132,    28, 15468,    26,   186, 21274,   166,\n",
       "           13,    39,    19,  1151,   475,  1478,  1019,   130,  1970,\n",
       "          122,    51,  1435,   346,  1847,  4172, 27634,    80,   368,\n",
       "        10077,  6503,   213, 11498,     2,  7881,    16,    22,    40,\n",
       "           28,   117,  7570,  5163,   114,    80,  1018,  1248,   213,\n",
       "           72,   331,   186,   285,    77,  1353,    92,  1865, 12749,\n",
       "            4,   936,    15,  4175,  1079,   105,     3,  9305,   692,\n",
       "          809,  9744,  5429,   812,     8,   497,    12,   436,   141,\n",
       "          668,  1170,   320,   869,   213,  2823,     6,   104,     6,\n",
       "          292, 13431,   527,    38,  3748,   379, 12352,   149,   527,\n",
       "         4814,    15,  1759,    95,    36,   527,   213,  2635,     7,\n",
       "            5,  5369,    90,   285,   131,    62,    19,   172,  2754,\n",
       "         1353,    78,    15,  1588,  2423,     2,    22,   127,  4477,\n",
       "        27439,  9275,  7583,     7,    13,   358, 29725,     4,    26,\n",
       "          288,  4872,   285, 29725,     4,     5,   413,  1838,  2002,\n",
       "         1775,    25,   441,  7511,    41,   806,  1019,   368, 10077,\n",
       "          132,   420,   186,   429,     3,   207,    25,  1233,   320,\n",
       "          213,   458,  4872,    41,  2850,  1687,   571,     6,    28,\n",
       "            6,   719,   412, 16711,     4, 15564,  1283,     2,    35,\n",
       "        15472,   102,    28,   335,   711,     3,   863,    31,  4332,\n",
       "          213,   331,  2663,   368, 10077, 24386,  1172,   105,    78,\n",
       "          647,   181,    19,    41,    40,  3565, 15994, 11105,  1044,\n",
       "          186,   117,  4001,  5352,    80,   809,    36,  1091,     7,\n",
       "            5,  2820,   132,   213,   797,     3,   252,    36,  5479,\n",
       "           36,   527,   213,   331,  2663,    22, 21302,    17,    68,\n",
       "         1838,   936,   186,   117, 16144,    17,    80,    15,  7122,\n",
       "         5928,   214,    68,     3,    56,  1353,   749,  6503,   691,\n",
       "          368, 10077,   799,     3,  9305,   692,   436,   668,  1170,\n",
       "          320,   869,   134,   527,    38,  1147,  3748,   990,     3,\n",
       "        17895,   102,   213,  2145,     2,   213, 13431,   127,  3611,\n",
       "           34, 10991,  5382,    13,   934,   206,   476,   539,   285,\n",
       "          143,    18,    46,   576,   213,  2297,   138,  3898,  4195,\n",
       "           22,   117,   108,    18, 21539,    17,    80,    36,   527,\n",
       "          213,   331,   132,   117,    28,  7570,  5163,   114,  2324,\n",
       "           80,   691, 20662,    16,    68,  2820,     3,     9,    86,\n",
       "           54,  1242,  1353,  7511,    22,   547,    15,  1759,    78,\n",
       "           36,   527,    31, 23885,   192,   131,  1353,   477,   809,\n",
       "           28,  1588,   320, 14012,     4,  2037,   809,    68,  3368,\n",
       "            2,    22,   127,     3,   368, 10077,  6122,   320, 25166,\n",
       "           36,   527,   213,   331,    40,   117,   762,    80, 22502,\n",
       "            5,    35,   206,    19,  4437,   105,     2,   186,   465,\n",
       "           22,   108,    18,   117, 15301,    80,    68,  4283,  2624,\n",
       "         1382,   527,  3409, 10273,   103,   412,  5754,     3,   305,\n",
       "         1353,  7456,     2,    22, 13293,     2,    78,   213,  1102,\n",
       "          527,    68, 17845,     4,    35,   285,    22,   640,    40,\n",
       "          320,  1399,    68,   236,  1019,  1083,   320,   126,   132,\n",
       "         2754,    22,   742,  1353,   163, 20218,  4878,   147,     3,\n",
       "          348,   213,    55,   527,   213,  6402, 24810,     5,     2,\n",
       "          368, 10077,     7,     5,   938,  1353, 10656,   527,  2518,\n",
       "            2,   103,  1353,  1613,    10,     1,     0,  3385, 10077,\n",
       "           23,    46,   233,    19,  8272,   527,  1147,  1865, 23891,\n",
       "         6412, 16346, 27439,  6774,  1628,     9,  2823,     6,   104,\n",
       "            6,   292,  1353,  5754,   527,   117, 26377,    16,    80,\n",
       "          186,   117,  6157,  1532,    80, 18453,  2125, 16346, 27439,\n",
       "         6774,  1628,  9744,  5429,   812,   793,    22,  1065, 22675,\n",
       "          185,  1019,   117,  8191,    16,   506,  2337,  6053, 27439,\n",
       "         6774,  1628,  9305,   692,   436,   141,   668,  1170,   320,\n",
       "          869,   213, 13431,   527,    38,  3748,   824,  4979, 16346,\n",
       "        27439,  6774,  7583,     7,  6062, 19330,    21,    80,  8998,\n",
       "          127, 27439,  9275,  1628,  4175, 27439,  9275,  7583,     7,\n",
       "          108,    18,    46,   576,   132,  2297,   138,     7,     1,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0],\n",
       "       [ 1369,   254, 26540,    23,  7257,  6342,   510,   668,  1170,\n",
       "          527,  8235,   412,  9389, 10924, 18829,    16,   412,   824,\n",
       "         5511,   285,   408,    78,    28, 13426,  6913,  9236, 10778,\n",
       "         8437,     2,   213,  4759,   527,  1480,   980,   134, 17459,\n",
       "        13980,     4,   123,   320,   213,   220,   381,   527,   213,\n",
       "          624,  3178,     3, 21336,  2398,   809,   112,     6,   112,\n",
       "          214,   175,   321,   486, 22103,     4, 13844,  7814, 21962,\n",
       "         5455,  3217,    22,  1048,   320,  3067,    78,    38,    15,\n",
       "         1711,  6009,    75,   482,   320, 22096,     4,    64,    28,\n",
       "           53,     6,    99,    99,     6,    53,    99,     6,    53,\n",
       "           66,     6,    99,   225,     6,   137,  2365,   285,   436,\n",
       "           72,   390,   320,   976,   186, 20704,     4,  1170,    78,\n",
       "          213,   924,     3,  6342,  5753,   278,    28,  4449,   650,\n",
       "          955,  3096,    78,    15,   270,  1207,   340,  7511,    22,\n",
       "         1552,  2232,   320, 13728,    14,   552,   213,  1232,     6,\n",
       "         9295,   733,  1779,     2,   122,  1298,     2,    40,  2408,\n",
       "          213,  2421,   499,   894,    78,   213, 15443, 11715,     3,\n",
       "        22393, 23331,   361,    11,  7257,  6342,  3222,   213,  3680,\n",
       "          102,  1436,    28,  9389,     6, 10924, 18829,    16,   409,\n",
       "        21918,    81,   809, 26154,  1092,  9876,   900,   379,  8573,\n",
       "          153,    11,  6342, 11922, 22737, 13844,  7814, 21962,  5455,\n",
       "         3217,   225,     6,   137,   132,   213,  3646,   284,   527,\n",
       "           31,   624,  3178,   604,  1262,  1207,   379, 20185,  1019,\n",
       "          103,    11, 13844,  7814, 21962,  5455,  3217,  8663,  6342,\n",
       "           38,   213,   138,   132,    31,  1207,     2,  1480, 23745,\n",
       "           21,   809,   112,     6,   112,   132,   213,  3646,   284,\n",
       "          379,  1109,  7565,     4,    11,  6342,   229,    28,   343,\n",
       "          527,  3069,   412,    22,  1754,    28,  4449,   650,    78,\n",
       "         1895,   736, 11969,     7,    13,   790, 29725,     4,    26,\n",
       "         7678,   196,     2,    13,  1893, 13787,    16,   379,    61,\n",
       "            2,    13,  1353,  2127,   320,   385,   809,   409,    79,\n",
       "        29725,   391,  7528,   824,  1859,  3898,   127,   213,   379,\n",
       "        26540,  4379,     2,  1779,    39,   169,   882,   213, 12846,\n",
       "         1808,  2020,  1702,   379,   346,     6,  3696,    81, 23995,\n",
       "        22504,  9473,    79,    78,  2613,     3,  6342,   379,    40,\n",
       "         5833,  1248,   163, 17421,   332,   282,   186, 13844,  7814,\n",
       "        21962,  5455,  3217,  7801,   132,   379,   855,     3,     9,\n",
       "           60,  1207,   340,   527,   213,   194,   408,   809,   128,\n",
       "            6,   118,   102,    22,   436,   379,  2900,   527,    28,\n",
       "         1857, 15914,   320,  1072,    28,  3294,   650,  3096,   246,\n",
       "          213,   314,     3,     9,   379,   728,     6,   104,     6,\n",
       "          292,  7565,     4,   540,    71,   213, 11863,    35,  1353,\n",
       "         2025,   179,   186,   213,   733,   379,  6671,   780,   691,\n",
       "         9917,   278,   163, 22554, 16949,     4,   285,   255,    18,\n",
       "          576,   163,   379,   277,   320,  4252,    64,   527,   213,\n",
       "         2775,     3, 13844,  7814, 21962,  5455,  3217,   379,    40,\n",
       "         1180,   823,    44,  7554,   192,  6342, 13798,   320,   423,\n",
       "          379,    15,    60,  2620,   457,     2,   412,    22,    40,\n",
       "          757,   213,   769,  1207,     3,   200,  7511,   213,   379,\n",
       "          175,   321,   486,   836,    28,  2033,   340,   809,   128,\n",
       "            6,   128,   213, 26540,  4379,   379,  7801,  1248,    28,\n",
       "        23492,   431, 23854,    81,   285,    15,  9201,   143,   124,\n",
       "         1290,   379,  2685,     3,  4612,   479,    11,  6342,   667,\n",
       "           15, 16781,   102, 10519,    28, 23764, 18974,  4449,   650,\n",
       "          320,   250,   213,  1207,   102, 20704,     4,  1170,   379,\n",
       "        11104, 12192,     5, 16926,     4,    11,  6342, 13798,  1248,\n",
       "           15,    60,  1583,     2,  7525,   141,  1777,   318,  1641,\n",
       "          379, 20911,   208,    11,    27,  7164, 12899, 23427,     5,\n",
       "           71,  1496,   412,  6342, 22909,     5,    28,  4449,   650,\n",
       "          132,  1516,   379,  2790,  3919, 12000,    11,  1165,     7,\n",
       "            5, 13844,  7814, 21962,  5455,  3217, 15110,     5,   145,\n",
       "           15, 17682,  1201,   809,   213,  6674,   924,   407,   379,\n",
       "          321,    32,  3331,    11,  6342,     7,     5, 16545,  5203,\n",
       "        16392,     5,  8928,     5,  1019,   213,  7565,     4,    78,\n",
       "           15,   138,   320,    28,  5111,  2365,   379,   252,   213,\n",
       "          769,   103, 27439,  9275,    29,  1353,   379,   213,   733,\n",
       "        10519,   525,  8352,   186,    44, 13947,  4371,   186,  6342,\n",
       "        29725,     4,     5,   269,   379,   385, 13830,   320,   413,\n",
       "         7511,    22,  1353, 14194, 25655,    16,  1577,   239,   213,\n",
       "          924, 29725,     4,     5,   379, 10722, 13375,     3,  6342,\n",
       "         4989,   635,    64,   527,  1223,    60,  3255,   809,   137,\n",
       "            6,   137,    35,   141,   379,  2685,  2232,   320,  1358,\n",
       "           78,     3,   348,   379,   253,     6,   137, 13844,  7814,\n",
       "        21962,  5455,  3217,     2,  1779,    40,    46,  2619,  1060,\n",
       "          186, 19451,  1248,   379,  4861, 24834, 20537,   360,   192,\n",
       "         6342,  1180,  9087,   103, 10022,   132,   213,   379,   924,\n",
       "            2,  1552,  8191,    17,     3,    69,  8663,    72, 11855,\n",
       "         5592,  4210,   954,   186,   146,   809,   379,   271,     6,\n",
       "          668,  4208,   132,    28,   620,   270,  1583,  1480,    15,\n",
       "         9201, 26831,  6789,   637,   379,   186, 10224, 17603,  4362,\n",
       "        20236,    71,   213,  3278,     3,    52,   379,  1353,    19,\n",
       "          683,  2170,   181, 15524,    35,    22,   229,    71,   213,\n",
       "          270,   719, 14400,   391,  4674,    78,  2754, 27090,  1289,\n",
       "        11115,  1838,  2249,    38,  1262,   807,   379,   107,   213,\n",
       "        21624, 10716,  5789,    47,   733,    10,     1,     0, 10727,\n",
       "        23745,    21,   132,   213,   604,     6,  1262,   624,  3178,\n",
       "         1207,    78,  1681, 16346, 27439,  6774,  1628, 24272,  1353,\n",
       "         9457,    78,  1895,   736,   809,    53,     6,    99,     2,\n",
       "           99,     6,    53,     2,    99,     6,    53,     2,    66,\n",
       "            6,    99,     2,   112,     6,   112, 16346, 27439,  6774,\n",
       "         1628,  6342,  2663,   213,  1207,    78,    15,   270,  1207,\n",
       "          340,     2,   225,     6,   137,   132,   213,  3646, 16346,\n",
       "        27439,  6774,  1628,     9, 10713,   409,     6, 21918,    81,\n",
       "         1790,   102, 20704,     4,  1170,   527,    55,    78,   924,\n",
       "        16346, 27439,  6774,  1628,    69,   169,  6108,  2359,     7,\n",
       "            5, 23995, 22504,  9473,    79,   132,   213,  1937,  1262,\n",
       "         2104,     1,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the corresponding iteger values\n",
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "double-iraqi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article and summary:\n",
      "\n",
      " 'Vindicated': Stephen Perry has been cleared of seven sexual offences\n",
      ". An insurance boss accused of hiring attractive teenage girls to ogle\n",
      "and grope has been cleared of seven sexual offences. Stephen Perry\n",
      "denied sexually assaulting two 17-year-olds when they worked for him\n",
      "at his Rotherham business throughout a trial at Sheffield Crown Court.\n",
      "The 58-year-old widow was today found not guilty of seven sexual\n",
      "offences against the two women but admitted some of his behaviour\n",
      "'could have been taken in the wrong way'. rothe . Speaking after the\n",
      "case, Mr Perry said he felt 'vindicated' by the outcome of the trial.\n",
      "'I feel I have been vindicated. These allegations were unfounded and I\n",
      "told the police as much. 'I am a friendly man and one of them\n",
      "described me as a fatherly figure which is about right. I encouraged a\n",
      "friendly, relaxed atmosphere at work and they misconstrued things.'\n",
      "The insurance chief added he would not hire teenagers to work at his\n",
      "firm in the future. 'I have made the decision like Lionel Blair once\n",
      "said that I'm not going to work with children any more. 'I now employ\n",
      "two 45-year-old women in the office who work for me.' During the trial\n",
      "it was alleged Mr Perry told recruitment managers to hire 'cracking'\n",
      "young women and that he liked employees 'young and fresh'. Sean\n",
      "Kilbride, who supplied candidates to the business, told jurors Mr\n",
      "Perry had instructed him: ''If they’re cracking, they’ll get the job,\n",
      "you know what I mean,' before adding he liked employees 'young and\n",
      "fresh'. 'He told me he was looking for 16 and 17-year-olds, preferably\n",
      "a girl,' Mr Kilbride said. One of the women alleged he grabbed her\n",
      "from behind while she was bent over in front of a filing cabinet,\n",
      "while the other claimed she felt 'uncomfortably' with the 'touchy,\n",
      "feely' boss. 'He was eyeing me up and down. I felt uncomfortable. I\n",
      "was trying to shrug it off, it was disgusting. He had his tongue out\n",
      "and was staring at me . 'He said: \"Don’t ever come to work in a skirt\n",
      "and glasses because I will not be held responsible for my actions if\n",
      "we are left alone.\"' Mr Perry denied the allegations, insisting he had\n",
      "a 'fatherly' relationship with the two women and that there was no\n",
      "sexual motive behind his behaviour towards them. Jurors at Sheffield\n",
      "Crown Court (above) took just 40 minutes to clear the 58-year-old\n",
      "widow of all charges . Accused of putting his hands over one of the\n",
      "girl's faces so that she would not see what was on his computer\n",
      "screen, he said: 'I don’t know where that’s come from.' Both were 17\n",
      "when they worked for Mr Perry in 2012 and 2013. They were sent to the\n",
      "company where they earned £100-a-week as apprentice clerks, but quit\n",
      "after a few months. During their interviews the women claimed Mr Perry\n",
      "quizzed them on whether or not they had boyfriends and 'oohed' at one\n",
      "woman's bottom in the office. On one occasion one of the women claimed\n",
      "he grabbed her from behind and 'rubbed' his crotch against her. This\n",
      "was strong denied by Mr Perry throughout. Jurors took 40 minutes to\n",
      "clear him of all seven charges brought. Speaking after the trial, the\n",
      "widow said: 'In hindsight I probably did say things that could have\n",
      "been taken the wrong way,' adding he 'may have comforted' one of the\n",
      "women in 'a fatherly manner' by patting her bottom. The only other\n",
      "contact was when he put his hands on one of their shoulders while she\n",
      "was working at a computer to poke fun at her height, he said. Mr Perry\n",
      "admitted to observing one of the women had 'big' breasts but did not\n",
      "touch them, and says he may have 'touched' her thigh instead of\n",
      "slapping it as accused. She was hired, he insisted, on the basis of\n",
      "her CV but that he once had to tell her off for coming to work in what\n",
      "he thought was an inappropriate blouse. At the time of the alleged\n",
      "assaults, Mr Perry's wife was dying of cancer, it was\n",
      "heard.<EOS><pad>StephenPerry has been found not guilty of seven sexual\n",
      "offences . The 58-year-old was accused of 'ogling' and 'groping'\n",
      "teenage employees . Sheffield Crown Court told he asked recruiters for\n",
      "'cracking young girls' Jurors took just 40 minutes to clear the widow\n",
      "of all charges this afternoon . 'Vindicated' boss said behaviour 'may\n",
      "have been taken in wrong way'<EOS><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# above input batch consists:\n",
    "#     all the values corresponding to words, first 1 represents the <EOS> of the article followed by 0 (pads)\n",
    "#     after the first 0, other values show the summary words and the second 1 represent the <EOS> tag for summary\n",
    "#       All the other 0s are to maintain the consistancy of the  length - max length specified in the bucket \n",
    "# show the processes input data batch\n",
    "print(\"Article and summary:\\n\\n\",detokenize(input_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "solid-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the structure is article <EOS><PADs>article summary <EOS><pads>\n",
    "# loss is taken only on the summary using cross entropy as loss function\n",
    "#  Now create helper functions to create tensor and to display tensors using jax numpy array\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    \"\"\"input list of lists out put a tensor\"\"\"\n",
    "    return jnp.array(tensor)\n",
    "\n",
    "def display_tensor(tensor,name):\n",
    "    \"\"\" display the name and tensor\"\"\"\n",
    "    print(f'{name} shape: {tensor.shape}\\n')\n",
    "    print(f'{tensor}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-digest",
   "metadata": {},
   "source": [
    "# try with dummy data and build attention - dot product\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "proved-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dotproduct attention\n",
    "def DotProductAttention(query,key,value,mask):\n",
    "    \"\"\" dot product self attention\n",
    "    args: query - jax.intepreters.xla.DeviceArray: array of query representations with shape L_q by d\n",
    "    key jax.intepreters.xla.DeviceArray: array of query representation with shape L_k by d\n",
    "    value jax.intepreters.xla.DeviceArray: array of value representation with shpeL_k by d where L_v=L_k\n",
    "    mask jax.interpreters.sla.DeviceArray: attention mask, gates attention with shape L_q by L_k ( this is due to dot product)\n",
    "    returns jax.intperters.xla.DeviceArray: self-attention array for q,k,v arrays L_q by L_k\"\"\"\n",
    "    \n",
    "    assert query.shape[-1]==key.shape[-1]==value.shape[-1],\"Embeedding dimesions of q,k,v must be same\"\n",
    "#     get the depth dimentionality of the query embedding  for the scaling down the dot product\n",
    "    depth=query.shape[-1]\n",
    "    \n",
    "#     get the scaled query key dot product according to formula above\n",
    "    dots=jnp.matmul(query,jnp.swapaxes(key,-1,-2))/jnp.sqrt(depth)\n",
    "    \n",
    "#     now apply the mask\n",
    "    if mask is not None:\n",
    "        dots=jnp.where(mask,dots,jnp.full_like(dots,-1e9))\n",
    "    \n",
    "#     softmax\n",
    "    logsumexp=trax.fastmath.logsumexp(dots,axis=-1, keepdims=True)\n",
    "    \n",
    "#     now get the exponnential of dots minus logsumexp to get softmax\n",
    "    dots=jnp.exp(dots-logsumexp)\n",
    "#      now multiply by values to get the attention\n",
    "    attention=jnp.matmul(dots,value)\n",
    "    \n",
    "    return attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "expired-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now inpmelent the causal attention: multi headed attention with mask to attend only the words that occured before\n",
    "# 1. copute attention heads - get input with dimention (batch size, seqlen,n_heads X d_head) then splits the last(depth)\n",
    "# dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size X n_heads,seqlen,d_head)\n",
    "\n",
    "# 2. dot product self attention\n",
    "# 3. compute attention output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "chronic-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_heads_closure(n_heads,d_head):\n",
    "    \"\"\"Function that simulates environment inside CasualAttention \n",
    "    function.\n",
    "    Args: \n",
    "    d_head(int): dimensionality of heads.\n",
    "    n_heads (int): number of attention heads\n",
    "    Returns:\n",
    "    function: compute_attention_heads function\"\"\"\n",
    "    \n",
    "    def compute_attention_heads(x):\n",
    "        \"\"\"Compute attention heads.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape(batch_size,\n",
    "            seqlen,n_heads X d_head)\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen,d_head).\n",
    "        \"\"\"\n",
    "        #x batch dimension\n",
    "        batch_size=x.shape[0]\n",
    "        #length of sequence should be size of x's first dimension without counting batch dim\n",
    "        seqlen=x.shape[1]\n",
    "        #now change the shape from batch_size,seqlen,n_heads*d_head to batch_size,seqlen,n_heads,d_head\n",
    "        x=jnp.reshape(x,(batch_size,seqlen,n_heads,d_head))\n",
    "        #then transpose batch_size,seqlen,n_heads,d_head-->batch_size,n_heads,seqlen,d_head\n",
    "        #here the values within the tuple  are the indexes of the dimensions of x and need to rearrange them\n",
    "        x=jnp.transpose(x,(0,2,1,3))\n",
    "        #now reshape to batch_size,n_heads,seqlen,d_head -->batch_size*n_heads,seqlen,d_head\n",
    "        x=jnp.reshape(x,(-1,seqlen,d_head))\n",
    "        return x\n",
    "    return compute_attention_heads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "generous-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the dotproduct self attention with mask\n",
    "def dot_product_self_attention(q,k,v):\n",
    "    \"\"\"Masked dot product self attention\n",
    "    args: q (jax.interpreters.xla.DeviceArray): queries.\n",
    "          k (jax.interpreters.xla.DeviceArray):keys.\n",
    "          v (jax.interpreters.xla.DeviceArray):values\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor\"\"\"\n",
    "#     mask size should be size of L_q. q has shape of (batch_size,L_q,d)\n",
    "    mask_size=q.shape[-2]\n",
    "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
    "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
    "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
    "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return DotProductAttention(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "governmental-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute attention output, change the dims back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "renewable-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attention_output_closure(n_heads,d_head):\n",
    "    \"\"\"Function to simulate environment inside Causal attention function\n",
    "    input parameters: \n",
    "        n_deads: number of attention heads(int)\n",
    "        d_head:dimensionality of heads(int)\n",
    "        \n",
    "    return:\n",
    "        computed attention output function\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_attention_output(x):\n",
    "        \"\"\"\n",
    "        input parameters:\n",
    "        x: tensor of shape (batch_size X n_heads,sqlen,d_head)\n",
    "        Returns:\n",
    "        reshaped tensor (batch_size,seqlen,n_heads X d_head)\"\"\"\n",
    "        seqlen=x.shape[1]\n",
    "#         now reshape to (batch_size,n_heads,seqlen,d_head)\n",
    "        x=jnp.reshape(x,(-1,n_heads,seqlen,d_head))\n",
    "#     now  transpose to shape (batch_size,seqlen,n_heads,d_heads)\n",
    "        x=jnp.transpose(x,(0,2,1,3))\n",
    "#         now reshape back to allow concatenation\n",
    "        return jnp.reshape(x,(-1,seqlen,n_heads*d_head))\n",
    "    \n",
    "    return compute_attention_output\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "alleged-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now put everything together to causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "civilian-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CausalAttention(d_feature,\n",
    "                    n_heads,\n",
    "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
    "                    dot_product_self_attention=dot_product_self_attention,\n",
    "                    compute_attention_output_closure=compute_attention_output_closure,\n",
    "                    mode='train'):\n",
    "    \"\"\" transformer multi head attention.\n",
    "    input parameters:\n",
    "        d_feature : feature embedding dimensionality(int).\n",
    "        n_heads : number of attention heads\n",
    "        compute_attention_heads_closure (function): Closure around attention heads.\n",
    "        dot_product_self_attention (function): dot product function\n",
    "        compute_attention_output_closure(function):closure around attention output\n",
    "        mode : 'train' or 'eval' (sting)\n",
    "        \n",
    "    returns:\n",
    "        Multi-head self attention model\n",
    "    \"\"\"\n",
    "    \n",
    "#     need to ensure d_feature is multiplication of n_heads\n",
    "    assert d_feature%n_heads ==0\n",
    "    d_head=d_feature//n_heads\n",
    "    \n",
    "    ComputeAttentionHeads=tl.Fn('Attention_heads',compute_attention_heads_closure(n_heads,d_head),n_out=1)\n",
    "    \n",
    "    return tl.Serial(\n",
    "        tl.Branch(# create queries, keys and values\n",
    "            [tl.Dense(d_feature),ComputeAttentionHeads],\n",
    "            [tl.Dense(d_feature),ComputeAttentionHeads],\n",
    "            [tl.Dense(d_feature),ComputeAttentionHeads]),\n",
    "        tl.Fn('DotProductAttention',dot_product_self_attention,n_out=1),\n",
    "        tl.Fn('AttentionOutput',compute_attention_output_closure(n_heads,d_head),n_out=1), #to allow for parallel\n",
    "        tl.Dense(d_feature) #final dense layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "suburban-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Branch_out3[\n",
      "    [Dense_512, Attention_heads]\n",
      "    [Dense_512, Attention_heads]\n",
      "    [Dense_512, Attention_heads]\n",
      "  ]\n",
      "  DotProductAttention_in3\n",
      "  AttentionOutput\n",
      "  Dense_512\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(CausalAttention(d_feature=512, n_heads=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-collins",
   "metadata": {},
   "source": [
    "#### Transformer decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "metropolitan-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecoderBlock(d_model,depth_of_ff_layer,n_heads,dropout,mode,ff_activation):\n",
    "    \"\"\"This fuction returns a list of layers for a transformer decoder block.\n",
    "        The input is an activation tensor\n",
    "        \n",
    "        Inputs:\n",
    "            d_model:depth of embedding (int)\n",
    "            depth_of_ff_layer: depth_of_ff_layer\n",
    "            n_heads: number of attention heads\n",
    "            dropout: dropout rate (float)\n",
    "            mode: 'train' or 'eval' \n",
    "            ff_activation(function): the non linearity of feed-forward layer\n",
    "        Returns:\n",
    "            list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor\"\"\"\n",
    "    \n",
    "#     Create masked multi-head attention block using CausalAttention fucntion\n",
    "    causal_attention=CausalAttention(\n",
    "                                    d_model,\n",
    "                                    n_heads=n_heads,\n",
    "                                    mode=mode)\n",
    "    \n",
    "#     now create feed-forward block(list) with 2 dense layers with dropout and input normalised\n",
    "    feed_forward=[\n",
    "#         Normalised input layer\n",
    "        tl.LayerNorm(),\n",
    "#         add first feed forward dense layer( n units are depth_of_ff_layer)\n",
    "        tl.Dense(depth_of_ff_layer),\n",
    "        ff_activation(), #Relu activation\n",
    "        tl.Dropout(rate=dropout,mode=mode),\n",
    "#         add second feed forward layer\n",
    "        tl.Dense(d_model),\n",
    "        tl.Dropout(rate=dropout,mode=mode)\n",
    "    ]\n",
    "#     add two residual block\n",
    "    return [\n",
    "        tl.Residual(\n",
    "        #Normalise layer input\n",
    "        tl.LayerNorm(),\n",
    "        causal_attention,\n",
    "        tl.Dropout(rate=dropout,mode=mode)),\n",
    "        tl.Residual(\n",
    "        feed_forward),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "binary-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Serial[\n",
      "        Branch_out3[\n",
      "          [Dense_512, Attention_heads]\n",
      "          [Dense_512, Attention_heads]\n",
      "          [Dense_512, Attention_heads]\n",
      "        ]\n",
      "        DotProductAttention_in3\n",
      "        AttentionOutput\n",
      "        Dense_512\n",
      "      ]\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "], Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Dense_2048\n",
      "      Serial[\n",
      "        Relu\n",
      "      ]\n",
      "      Dropout\n",
      "      Dense_512\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "print(DecoderBlock(d_model=512, depth_of_ff_layer=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "executive-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together everything build language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "computational-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_language_model(vocab_size=33300,\n",
    "                               d_model=512,\n",
    "                               depth_of_ff_layer=2048,\n",
    "                               n_layers=6,\n",
    "                               n_heads=8,\n",
    "                               dropout=0.1,\n",
    "                               max_len=4096,\n",
    "                               mode='train',\n",
    "                               ff_activation=tl.Relu):\n",
    "    \"\"\"This function returns a transformer language model\n",
    "     input is tensors of tokens and this model uses the decorder part of the overall transformer\n",
    "     \n",
    "     input parameters:\n",
    "         vocab_size: vocab size (int)\n",
    "         d_model: depth of embedding(int)\n",
    "         depth_of_ff_layer: depth_of_ff_layer(int)\n",
    "         n_layers: number of decoder layers (int)\n",
    "         n_heads: number of attention heads (int)\n",
    "         dropout:dropout rate (float)\n",
    "         max_len: maximum symbol length for positional encording (int)\n",
    "         mode(str): train or eval\n",
    "         ff_activation (function): the non linearity in the feed forward layer\n",
    "         \n",
    "    returns:\n",
    "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
    "        to activations over a vocab set.\n",
    "         \n",
    "     \"\"\"\n",
    "    positional_encoder=[\n",
    "        #Add embedding layer of dimension (vocab_size,d_model)\n",
    "        tl.Embedding(vocab_size,d_model),\n",
    "        # dropout\n",
    "        tl.Dropout(rate=dropout,mode=mode),\n",
    "        # add positional encoding layer with max input length and specified mode\n",
    "        tl.PositionalEncoding(max_len=max_len,mode=mode)\n",
    "        ]\n",
    "    # now create stack - list of decoder blocks with n_layers with necessary parameters\n",
    "    decoder_blocks = [\n",
    "        DecoderBlock(d_model,depth_of_ff_layer,n_heads,dropout,mode,ff_activation) for _ in range(n_layers)\n",
    "    ]\n",
    "    \n",
    "    # now build the complete model\n",
    "    return tl.Serial(\n",
    "#         use teacher forcing for efficient training\n",
    "        tl.ShiftRight(mode=mode),\n",
    "#         add position encoder\n",
    "        positional_encoder,\n",
    "#         add decoder block\n",
    "        decoder_blocks,\n",
    "        tl.LayerNorm(),\n",
    "        tl.Dense(vocab_size),\n",
    "        tl.LogSoftmax()\n",
    "    \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "tender-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Serial[\n",
      "    ShiftRight(1)\n",
      "  ]\n",
      "  Embedding_33300_512\n",
      "  Dropout\n",
      "  PositionalEncoding\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Serial[\n",
      "          Branch_out3[\n",
      "            [Dense_512, Attention_heads]\n",
      "            [Dense_512, Attention_heads]\n",
      "            [Dense_512, Attention_heads]\n",
      "          ]\n",
      "          DotProductAttention_in3\n",
      "          AttentionOutput\n",
      "          Dense_512\n",
      "        ]\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Serial[\n",
      "          Relu\n",
      "        ]\n",
      "        Dropout\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  LayerNorm\n",
      "  Dense_33300\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the Transformer\n",
    "print(transformer_language_model(n_layers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "conventional-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "according-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "def training_loop(transformer_language_model,train_gen,eval_gen,output_dir=\"./\"):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        transformer_language_model (trax.layers.combinators.Serial):previously built model\n",
    "        train_gen(generator): Training stream of data.\n",
    "        eval_gen(generator): Evaluation stream of data\n",
    "        output dir(str): loacation to save the train model\n",
    "        \n",
    "    returns:\n",
    "        trax.supervised.training.Loop: Training loop.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir=os.path.expanduser(output_dir)\n",
    "    lr_schedule=trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000,max_value=0.01)\n",
    "    \n",
    "    train_task=training.TrainTask(\n",
    "        labeled_data=train_gen,\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        optimizer=trax.optimizers.Adam(0.01),\n",
    "        lr_schedule=lr_schedule,\n",
    "        n_steps_per_checkpoint=10)\n",
    "    \n",
    "    eval_task=training.EvalTask(\n",
    "        labeled_data=eval_gen,\n",
    "        metrics=[tl.CrossEntropyLoss(),tl.Accuracy()])\n",
    "    \n",
    "    loop=training.Loop(transformer_language_model(                \n",
    "                                            d_model=512,\n",
    "                                            depth_of_ff_layer=2048,\n",
    "                                            n_layers=6,\n",
    "                                            n_heads=8,\n",
    "                                            mode='train'),\n",
    "                                            train_task,\n",
    "                                            eval_tasks=[eval_task],\n",
    "                                            output_dir=output_dir)\n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 55144980\n",
      "Step      1: Ran 1 train steps in 56.83 secs\n",
      "Step      1: train CrossEntropyLoss |  10.46865654\n",
      "Step      1: eval  CrossEntropyLoss |  10.43511200\n",
      "Step      1: eval          Accuracy |  0.00000000\n"
     ]
    }
   ],
   "source": [
    "loop = training_loop(transformer_language_model, train_batch_stream, eval_batch_stream)\n",
    "loop.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-lewis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-zoning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-dayton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-pasta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-table",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-world",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-building",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-catholic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-network",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-chicken",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-active",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
